{
  
    
        "post0": {
            "title": "ART Classifier",
            "content": "%config IPCompleter.greedy=True import fastbook fastbook.setup_book() from fastbook import * from fastai.vision.widgets import * . import pandas as pd import numpy as np . df = pd.read_csv(&#39;artists.csv&#39;); names = df[&#39;name&#39;] names = names.to_list() names . [&#39;Amedeo Modigliani&#39;, &#39;Vasiliy Kandinskiy&#39;, &#39;Diego Rivera&#39;, &#39;Claude Monet&#39;, &#39;Rene Magritte&#39;, &#39;Salvador Dali&#39;, &#39;Edouard Manet&#39;, &#39;Andrei Rublev&#39;, &#39;Vincent van Gogh&#39;, &#39;Gustav Klimt&#39;, &#39;Hieronymus Bosch&#39;, &#39;Kazimir Malevich&#39;, &#39;Mikhail Vrubel&#39;, &#39;Pablo Picasso&#39;, &#39;Peter Paul Rubens&#39;, &#39;Pierre-Auguste Renoir&#39;, &#39;Francisco Goya&#39;, &#39;Frida Kahlo&#39;, &#39;El Greco&#39;, &#39;Albrecht Dürer&#39;, &#39;Alfred Sisley&#39;, &#39;Pieter Bruegel&#39;, &#39;Marc Chagall&#39;, &#39;Giotto di Bondone&#39;, &#39;Sandro Botticelli&#39;, &#39;Caravaggio&#39;, &#39;Leonardo da Vinci&#39;, &#39;Diego Velazquez&#39;, &#39;Henri Matisse&#39;, &#39;Jan van Eyck&#39;, &#39;Edgar Degas&#39;, &#39;Rembrandt&#39;, &#39;Titian&#39;, &#39;Henri de Toulouse-Lautrec&#39;, &#39;Gustave Courbet&#39;, &#39;Camille Pissarro&#39;, &#39;William Turner&#39;, &#39;Edvard Munch&#39;, &#39;Paul Cezanne&#39;, &#39;Eugene Delacroix&#39;, &#39;Henri Rousseau&#39;, &#39;Georges Seurat&#39;, &#39;Paul Klee&#39;, &#39;Piet Mondrian&#39;, &#39;Joan Miro&#39;, &#39;Andy Warhol&#39;, &#39;Paul Gauguin&#39;, &#39;Raphael&#39;, &#39;Michelangelo&#39;, &#39;Jackson Pollock&#39;] . conf_id = &quot;efb1b149-c219-4091-be6d-14a279c405c4&quot; key_id = &quot;1be3ada0f2a649d087e9fb39798485a0&quot; #Define method to search bing for images def search_images_bing_new(key, term, customConfigId, min_sz=128): url = &#39;https://api.bing.microsoft.com/v7.0/custom/images/search?&#39; + &#39;q=&#39; + term + &#39;&amp;&#39; + &#39;customconfig=&#39; + customConfigId + &#39;&amp;&#39; + &#39;count=150&#39; r = requests.get(url, headers={&#39;Ocp-Apim-Subscription-Key&#39;: key}) search_results = r.json() return L([img[&quot;thumbnailUrl&quot;] for img in search_results[&quot;value&quot;][:150]]) . image_types = names path = Path(&#39;art&#39;) if not path.exists(): path.mkdir() for o in image_types: dest = (path/o) dest.mkdir(exist_ok=True) results = search_images_bing_new(key_id, o, conf_id) download_images(dest, urls=results) . fns = get_image_files(path) failed = verify_images(fns) failed.map(Path.unlink) . (#0) [] . artist = DataBlock( blocks=(ImageBlock, CategoryBlock), get_items=get_image_files, splitter=RandomSplitter(valid_pct=0.2, seed=42), get_y=parent_label, item_tfms=RandomResizedCrop(224, min_scale=0.5) ) . dls = artist.dataloaders(path) dls.valid.show_batch(max_n=8, nrows=2) . model = cnn_learner(dls, resnet18, metrics=error_rate) model.fine_tune(4) . epoch train_loss valid_loss error_rate time . 0 | 3.640395 | 1.958444 | 0.511409 | 00:57 | . epoch train_loss valid_loss error_rate time . 0 | 2.094822 | 1.472021 | 0.395302 | 01:14 | . 1 | 1.512678 | 1.203370 | 0.321477 | 01:14 | . 2 | 1.041037 | 1.054622 | 0.285235 | 01:14 | . 3 | 0.746764 | 1.025786 | 0.268456 | 01:14 | . interpreter = ClassificationInterpretation.from_learner(model) interpreter.plot_confusion_matrix() . interpreter.plot_top_losses(1, nrows=3) . cleaner = ImageClassifierCleaner(model) cleaner . FileNotFoundError Traceback (most recent call last) &lt;ipython-input-28-05c9e6076498&gt; in &lt;module&gt; -&gt; 1 cleaner = ImageClassifierCleaner(model) 2 cleaner /opt/conda/envs/fastai/lib/python3.8/site-packages/fastai/vision/widgets.py in __init__(self, learn, **kwargs) 79 self.dd_cats = Dropdown(options=vocab) 80 self.dd_ds = Dropdown(options=(&#39;Train&#39;,&#39;Valid&#39;)) &gt; 81 self.iwis = _get_iw_info(learn,0),_get_iw_info(learn,1) 82 self.dd_ds.observe(self.on_change_ds, &#39;value&#39;) 83 self.dd_cats.observe(self.on_change_ds, &#39;value&#39;) /opt/conda/envs/fastai/lib/python3.8/site-packages/fastai/vision/widgets.py in _get_iw_info(learn, ds_idx) 66 def _get_iw_info(learn, ds_idx=0): 67 dl = learn.dls[ds_idx].new(shuffle=False, drop_last=False) &gt; 68 inp,probs,targs,preds,losses = learn.get_preds(dl=dl, with_input=True, with_loss=True, with_decoded=True) 69 inp,targs = L(zip(*dl.decode_batch((inp,targs), max_n=9999))) 70 return L([dl.dataset.items,targs,losses]).zip() /opt/conda/envs/fastai/lib/python3.8/site-packages/fastai/learner.py in get_preds(self, ds_idx, dl, with_input, with_decoded, with_loss, act, inner, reorder, cbs, **kwargs) 235 if with_loss: ctx_mgrs.append(self.loss_not_reduced()) 236 with ContextManagers(ctx_mgrs): --&gt; 237 self._do_epoch_validate(dl=dl) 238 if act is None: act = getattr(self.loss_func, &#39;activation&#39;, noop) 239 res = cb.all_tensors() /opt/conda/envs/fastai/lib/python3.8/site-packages/fastai/learner.py in _do_epoch_validate(self, ds_idx, dl) 185 if dl is None: dl = self.dls[ds_idx] 186 self.dl = dl --&gt; 187 with torch.no_grad(): self._with_events(self.all_batches, &#39;validate&#39;, CancelValidException) 188 189 def _do_epoch(self): /opt/conda/envs/fastai/lib/python3.8/site-packages/fastai/learner.py in _with_events(self, f, event_type, ex, final) 152 153 def _with_events(self, f, event_type, ex, final=noop): --&gt; 154 try: self(f&#39;before_{event_type}&#39;) ;f() 155 except ex: self(f&#39;after_cancel_{event_type}&#39;) 156 finally: self(f&#39;after_{event_type}&#39;) ;final() /opt/conda/envs/fastai/lib/python3.8/site-packages/fastai/learner.py in all_batches(self) 158 def all_batches(self): 159 self.n_iter = len(self.dl) --&gt; 160 for o in enumerate(self.dl): self.one_batch(*o) 161 162 def _do_one_batch(self): /opt/conda/envs/fastai/lib/python3.8/site-packages/fastai/data/load.py in __iter__(self) 99 self.before_iter() 100 self.__idxs=self.get_idxs() # called in context of main process (not workers/subprocesses) --&gt; 101 for b in _loaders[self.fake_l.num_workers==0](self.fake_l): 102 if self.device is not None: b = to_device(b, self.device) 103 yield self.after_batch(b) /opt/conda/envs/fastai/lib/python3.8/site-packages/torch/utils/data/dataloader.py in __next__(self) 433 if self._sampler_iter is None: 434 self._reset() --&gt; 435 data = self._next_data() 436 self._num_yielded += 1 437 if self._dataset_kind == _DatasetKind.Iterable and /opt/conda/envs/fastai/lib/python3.8/site-packages/torch/utils/data/dataloader.py in _next_data(self) 1063 if len(self._task_info[self._rcvd_idx]) == 2: 1064 data = self._task_info.pop(self._rcvd_idx)[1] -&gt; 1065 return self._process_data(data) 1066 1067 assert not self._shutdown and self._tasks_outstanding &gt; 0 /opt/conda/envs/fastai/lib/python3.8/site-packages/torch/utils/data/dataloader.py in _process_data(self, data) 1109 self._try_put_index() 1110 if isinstance(data, ExceptionWrapper): -&gt; 1111 data.reraise() 1112 return data 1113 /opt/conda/envs/fastai/lib/python3.8/site-packages/torch/_utils.py in reraise(self) 426 # have message field 427 raise self.exc_type(message=msg) --&gt; 428 raise self.exc_type(msg) 429 430 FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 4. Original Traceback (most recent call last): File &#34;/opt/conda/envs/fastai/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py&#34;, line 198, in _worker_loop data = fetcher.fetch(index) File &#34;/opt/conda/envs/fastai/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py&#34;, line 34, in fetch data = next(self.dataset_iter) File &#34;/opt/conda/envs/fastai/lib/python3.8/site-packages/fastai/data/load.py&#34;, line 110, in create_batches yield from map(self.do_batch, self.chunkify(res)) File &#34;/opt/conda/envs/fastai/lib/python3.8/site-packages/fastcore/basics.py&#34;, line 211, in chunked res = list(itertools.islice(it, chunk_sz)) File &#34;/opt/conda/envs/fastai/lib/python3.8/site-packages/fastai/data/load.py&#34;, line 125, in do_item try: return self.after_item(self.create_item(s)) File &#34;/opt/conda/envs/fastai/lib/python3.8/site-packages/fastai/data/load.py&#34;, line 131, in create_item def create_item(self, s): return next(self.it) if s is None else self.dataset[s] File &#34;/opt/conda/envs/fastai/lib/python3.8/site-packages/fastai/data/core.py&#34;, line 314, in __getitem__ res = tuple([tl[it] for tl in self.tls]) File &#34;/opt/conda/envs/fastai/lib/python3.8/site-packages/fastai/data/core.py&#34;, line 314, in &lt;listcomp&gt; res = tuple([tl[it] for tl in self.tls]) File &#34;/opt/conda/envs/fastai/lib/python3.8/site-packages/fastai/data/core.py&#34;, line 280, in __getitem__ return self._after_item(res) if is_indexer(idx) else res.map(self._after_item) File &#34;/opt/conda/envs/fastai/lib/python3.8/site-packages/fastai/data/core.py&#34;, line 242, in _after_item def _after_item(self, o): return self.tfms(o) File &#34;/opt/conda/envs/fastai/lib/python3.8/site-packages/fastcore/transform.py&#34;, line 198, in __call__ def __call__(self, o): return compose_tfms(o, tfms=self.fs, split_idx=self.split_idx) File &#34;/opt/conda/envs/fastai/lib/python3.8/site-packages/fastcore/transform.py&#34;, line 150, in compose_tfms x = f(x, **kwargs) File &#34;/opt/conda/envs/fastai/lib/python3.8/site-packages/fastcore/transform.py&#34;, line 73, in __call__ def __call__(self, x, **kwargs): return self._call(&#39;encodes&#39;, x, **kwargs) File &#34;/opt/conda/envs/fastai/lib/python3.8/site-packages/fastcore/transform.py&#34;, line 83, in _call return self._do_call(getattr(self, fn), x, **kwargs) File &#34;/opt/conda/envs/fastai/lib/python3.8/site-packages/fastcore/transform.py&#34;, line 89, in _do_call return retain_type(f(x, **kwargs), x, ret) File &#34;/opt/conda/envs/fastai/lib/python3.8/site-packages/fastcore/dispatch.py&#34;, line 117, in __call__ return f(*args, **kwargs) File &#34;/opt/conda/envs/fastai/lib/python3.8/site-packages/fastai/vision/core.py&#34;, line 110, in create return cls(load_image(fn, **merge(cls._open_args, kwargs))) File &#34;/opt/conda/envs/fastai/lib/python3.8/site-packages/fastai/vision/core.py&#34;, line 85, in load_image im = Image.open(fn) File &#34;/opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py&#34;, line 2891, in open fp = builtins.open(filename, &#34;rb&#34;) FileNotFoundError: [Errno 2] No such file or directory: &#39;/notebooks/art/Raphael/00000102.jpg&#39; . for idx in cleaner.delete(): cleaner.fns[idx].unlink() # for moce to different category # for idx,cat in cleaner.change(): shutil.move(str(cleaner.fns[idx]), path/cat) . btn_upload = widgets.FileUpload() btn_upload . img = PILImage.create(btn_upload.data[-1]) . pred,pred_idx,probs = model.predict(img) . lbl_pred = widgets.Label() lbl_pred.value = f&#39;Prediction: {pred}; Probability: {probs[pred_idx]:.04f}&#39; lbl_pred .",
            "url": "https://jp97.github.io/SW-AI-Blog/jupyter/2021/02/18/Art-Classification.html",
            "relUrl": "/jupyter/2021/02/18/Art-Classification.html",
            "date": " • Feb 18, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Food Classifier",
            "content": "%config IPCompleter.greedy=True . import fastbook fastbook.setup_book() from fastbook import * from fastai.vision.widgets import * . conf_id = &quot;efb1b149-c219-4091-be6d-14a279c405c4&quot; key_id = &quot;1be3ada0f2a649d087e9fb39798485a0&quot; #Define method to search bing for images def search_images_bing_new(key, term, customConfigId, min_sz=128): url = &#39;https://api.bing.microsoft.com/v7.0/custom/images/search?&#39; + &#39;q=&#39; + term + &#39;&amp;&#39; + &#39;customconfig=&#39; + customConfigId + &#39;&amp;&#39; + &#39;count=150&#39; r = requests.get(url, headers={&#39;Ocp-Apim-Subscription-Key&#39;: key}) search_results = r.json() return L([img[&quot;thumbnailUrl&quot;] for img in search_results[&quot;value&quot;][:150]]) . images_url = search_images_bing_new(key_id, &#39;hotdog&#39;, conf_id) print(len(images_url)) . 150 . destination = &#39;image/hotdog.jpg&#39; download_url(images_url[0], destination) im = Image.open(destination) im.to_thumb(128,128) . image_types = &#39;hotdog&#39;, &#39;pizza&#39;, &#39;burger&#39;, &#39;chickennuggets&#39;, &#39;pommes Frittes&#39;, &#39;kebab&#39;, &#39;churros&#39;, &#39;sushi&#39;, &#39;pasta&#39; path = Path(&#39;foods&#39;) if not path.exists(): path.mkdir() for o in image_types: dest = (path/o) dest.mkdir(exist_ok=True) results = search_images_bing_new(key_id, o, conf_id) download_images(dest, urls=results) . fns = get_image_files(path) failed = verify_images(fns) failed.map(Path.unlink) . (#0) [] . food = DataBlock( blocks=(ImageBlock, CategoryBlock), get_items=get_image_files, splitter=RandomSplitter(valid_pct=0.2, seed=42), get_y=parent_label, item_tfms=RandomResizedCrop(224, min_scale=0.5) ) . dls = food.dataloaders(path) dls.valid.show_batch(max_n=8, nrows=2) . model = cnn_learner(dls, resnet18, metrics=error_rate) model.fine_tune(4) . epoch train_loss valid_loss error_rate time . 0 | 2.443678 | 0.590293 | 0.197761 | 00:11 | . epoch train_loss valid_loss error_rate time . 0 | 0.716741 | 0.433649 | 0.126866 | 00:13 | . 1 | 0.526972 | 0.360585 | 0.115672 | 00:14 | . 2 | 0.373124 | 0.333442 | 0.119403 | 00:13 | . 3 | 0.285994 | 0.331162 | 0.119403 | 00:14 | . interpreter = ClassificationInterpretation.from_learner(model) interpreter.plot_confusion_matrix() . interpreter.plot_top_losses(1, nrows=1) . cleaner = ImageClassifierCleaner(model) cleaner . for idx in cleaner.delete(): cleaner.fns[idx].unlink() # for moce to different category # for idx,cat in cleaner.change(): shutil.move(str(cleaner.fns[idx]), path/cat) . model.export() . path = Path() path.ls(file_exts=&#39;.pkl&#39;) . (#1) [Path(&#39;export.pkl&#39;)] . btn_upload = widgets.FileUpload() btn_upload . img = PILImage.create(btn_upload.data[-1]) . out_pl = widgets.Output() out_pl.clear_output() with out_pl: display(img.to_thumb(128,128)) out_pl . pred,pred_idx,probs = model.predict(img) . lbl_pred = widgets.Label() lbl_pred.value = f&#39;Prediction: {pred}; Probability: {probs[pred_idx]:.04f}&#39; lbl_pred . btn_run = widgets.Button(description=&#39;Classify&#39;) btn_run . def on_click_classify(change): img = PILImage.create(btn_upload.data[-1]) out_pl.clear_output() with out_pl: display(img.to_thumb(128,128)) pred,pred_idx,probs = learn_inf.predict(img) lbl_pred.value = f&#39;Prediction: {pred}; Probability: {probs[pred_idx]:.04f}&#39; btn_run.on_click(on_click_classify) . VBox([widgets.Label(&#39;Select your bear!&#39;), btn_upload, btn_run, out_pl, lbl_pred]) .",
            "url": "https://jp97.github.io/SW-AI-Blog/jupyter/2021/02/17/Food-Classifier.html",
            "relUrl": "/jupyter/2021/02/17/Food-Classifier.html",
            "date": " • Feb 17, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "HOTDOGGER",
            "content": "# Fast book setup import fastbook fastbook.setup_book() from fastbook import * from fastai.vision.widgets import * . conf_id = &quot;efb1b149-c219-4091-be6d-14a279c405c4&quot; key_id = &quot;1be3ada0f2a649d087e9fb39798485a0&quot; #Define method to search bing for images def search_images_bing_new(key, term, customConfigId, min_sz=128): url = &#39;https://api.bing.microsoft.com/v7.0/custom/images/search?&#39; + &#39;q=&#39; + term + &#39;&amp;&#39; + &#39;customconfig=&#39; + customConfigId + &#39;&amp;&#39; + &#39;count=150&#39; r = requests.get(url, headers={&#39;Ocp-Apim-Subscription-Key&#39;: key}) search_results = r.json() return L([img[&quot;thumbnailUrl&quot;] for img in search_results[&quot;value&quot;][:150]]) . ims = search_images_bing_new(key_id, &#39;hot dog&#39;, conf_id) len(ims) . 150 . dest = &#39;images/hot_dog.jpg&#39; download_url(ims[0], dest) im = Image.open(dest) im.to_thumb(128,128) . image_types = &#39;hot dog&#39;, &#39;burger&#39; path = Path(&#39;foods&#39;) if not path.exists(): path.mkdir() for o in image_types: dest = (path/o) dest.mkdir(exist_ok=True) results = search_images_bing_new(key_id, o, conf_id) download_images(dest, urls=results) fns = get_image_files(path) failed = verify_images(fns) failed.map(Path.unlink) . (#0) [] . food = DataBlock( blocks=(ImageBlock, CategoryBlock), get_items=get_image_files, splitter=RandomSplitter(valid_pct=.2, seed = 42), get_y=parent_label, item_tfms=RandomResizedCrop(224, min_scale=0.5) ) dls = food.dataloaders(path) dls.valid.show_batch(max_n=4, nrows=1) . learn = cnn_learner(dls, resnet18, metrics=error_rate) learn.fine_tune(4) . epoch train_loss valid_loss error_rate time . 0 | 1.226112 | 0.206438 | 0.083333 | 00:03 | . epoch train_loss valid_loss error_rate time . 0 | 0.343744 | 0.164238 | 0.050000 | 00:04 | . 1 | 0.246327 | 0.101516 | 0.066667 | 00:03 | . 2 | 0.167483 | 0.097955 | 0.050000 | 00:03 | . 3 | 0.126819 | 0.106567 | 0.050000 | 00:03 | . interp = ClassificationInterpretation.from_learner(learn) interp.plot_confusion_matrix() interp.plot_top_losses(5, nrows=1) . cleaner = ImageClassifierCleaner(learn) cleaner . for idx in cleaner.delete(): cleaner.fns[idx].unlink() . btn_upload = widgets.FileUpload() btn_upload . img = PILImage.create(btn_upload.data[-1]) . out_pl = widgets.Output() out_pl.clear_output() with out_pl: display(img.to_thumb(128,128)) out_pl . pred,pred_idx,probs = learn_inf.predict(img) . NameError Traceback (most recent call last) &lt;ipython-input-18-9a18687b977c&gt; in &lt;module&gt; -&gt; 1 pred,pred_idx,probs = learn_inf.predict(img) NameError: name &#39;learn_inf&#39; is not defined . lbl_pred = widgets.Label() lbl_pred.value = f&#39;Prediction: {pred}; Probability: {probs[pred_idx]:.04f}&#39; lbl_pred . NameError Traceback (most recent call last) &lt;ipython-input-17-fb9bca207f6f&gt; in &lt;module&gt; 1 lbl_pred = widgets.Label() -&gt; 2 lbl_pred.value = f&#39;Prediction: {pred}; Probability: {probs[pred_idx]:.04f}&#39; 3 lbl_pred NameError: name &#39;pred&#39; is not defined . btn_run = widgets.Button(description=&#39;Classify&#39;) btn_run . def on_click_classify(change): img = PILImage.create(btn_upload.data[-1]) out_pl.clear_output() with out_pl: display(img.to_thumb(128,128)) pred,pred_idx,probs = learn_inf.predict(img) lbl_pred.value = f&#39;Prediction: {pred}; Probability: {probs[pred_idx]:.04f}&#39; btn_run.on_click(on_click_classify) . VBox([widgets.Label(&#39;Select your bear!&#39;), btn_upload, btn_run, out_pl, lbl_pred]) . !pip install voila !jupyter serverextension enable voila --sys-prefix . Collecting voila Downloading voila-0.2.6-py3-none-any.whl (1.9 MB) |████████████████████████████████| 1.9 MB 15.1 MB/s eta 0:00:01 Requirement already satisfied: nbclient&lt;0.6,&gt;=0.4.0 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from voila) (0.5.1) Collecting nbconvert&lt;7,&gt;=6.0.0 Downloading nbconvert-6.0.7-py3-none-any.whl (552 kB) |████████████████████████████████| 552 kB 48.8 MB/s eta 0:00:01 Collecting jupyter-server&lt;2.0.0,&gt;=0.3.0 Downloading jupyter_server-1.3.0-py3-none-any.whl (188 kB) |████████████████████████████████| 188 kB 51.0 MB/s eta 0:00:01 Requirement already satisfied: jupyter-client&lt;7,&gt;=6.1.3 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from voila) (6.1.7) Requirement already satisfied: traitlets&gt;=4.2 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from nbclient&lt;0.6,&gt;=0.4.0-&gt;voila) (5.0.5) Requirement already satisfied: async-generator in /opt/conda/envs/fastai/lib/python3.8/site-packages (from nbclient&lt;0.6,&gt;=0.4.0-&gt;voila) (1.10) Requirement already satisfied: nbformat&gt;=5.0 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from nbclient&lt;0.6,&gt;=0.4.0-&gt;voila) (5.0.8) Requirement already satisfied: nest-asyncio in /opt/conda/envs/fastai/lib/python3.8/site-packages (from nbclient&lt;0.6,&gt;=0.4.0-&gt;voila) (1.4.3) Requirement already satisfied: jupyterlab-pygments in /opt/conda/envs/fastai/lib/python3.8/site-packages (from nbconvert&lt;7,&gt;=6.0.0-&gt;voila) (0.1.2) Requirement already satisfied: defusedxml in /opt/conda/envs/fastai/lib/python3.8/site-packages (from nbconvert&lt;7,&gt;=6.0.0-&gt;voila) (0.6.0) Requirement already satisfied: testpath in /opt/conda/envs/fastai/lib/python3.8/site-packages (from nbconvert&lt;7,&gt;=6.0.0-&gt;voila) (0.4.4) Requirement already satisfied: pygments&gt;=2.4.1 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from nbconvert&lt;7,&gt;=6.0.0-&gt;voila) (2.7.2) Requirement already satisfied: bleach in /opt/conda/envs/fastai/lib/python3.8/site-packages (from nbconvert&lt;7,&gt;=6.0.0-&gt;voila) (3.2.1) Requirement already satisfied: mistune&lt;2,&gt;=0.8.1 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from nbconvert&lt;7,&gt;=6.0.0-&gt;voila) (0.8.4) Requirement already satisfied: pandocfilters&gt;=1.4.1 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from nbconvert&lt;7,&gt;=6.0.0-&gt;voila) (1.4.2) Requirement already satisfied: jupyter-core in /opt/conda/envs/fastai/lib/python3.8/site-packages (from nbconvert&lt;7,&gt;=6.0.0-&gt;voila) (4.7.0) Requirement already satisfied: jinja2&gt;=2.4 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from nbconvert&lt;7,&gt;=6.0.0-&gt;voila) (2.11.2) Requirement already satisfied: entrypoints&gt;=0.2.2 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from nbconvert&lt;7,&gt;=6.0.0-&gt;voila) (0.3) Requirement already satisfied: ipython-genutils in /opt/conda/envs/fastai/lib/python3.8/site-packages (from jupyter-server&lt;2.0.0,&gt;=0.3.0-&gt;voila) (0.2.0) Requirement already satisfied: prometheus-client in /opt/conda/envs/fastai/lib/python3.8/site-packages (from jupyter-server&lt;2.0.0,&gt;=0.3.0-&gt;voila) (0.9.0) Requirement already satisfied: pyzmq&gt;=17 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from jupyter-server&lt;2.0.0,&gt;=0.3.0-&gt;voila) (20.0.0) Requirement already satisfied: Send2Trash in /opt/conda/envs/fastai/lib/python3.8/site-packages (from jupyter-server&lt;2.0.0,&gt;=0.3.0-&gt;voila) (1.5.0) Requirement already satisfied: terminado&gt;=0.8.3 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from jupyter-server&lt;2.0.0,&gt;=0.3.0-&gt;voila) (0.9.1) Requirement already satisfied: tornado&gt;=6.1.0 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from jupyter-server&lt;2.0.0,&gt;=0.3.0-&gt;voila) (6.1) Collecting anyio&gt;=2.0.2 Downloading anyio-2.1.0-py3-none-any.whl (64 kB) |████████████████████████████████| 64 kB 4.1 MB/s eta 0:00:01 Requirement already satisfied: python-dateutil&gt;=2.1 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from jupyter-client&lt;7,&gt;=6.1.3-&gt;voila) (2.8.1) Requirement already satisfied: jsonschema!=2.5.0,&gt;=2.4 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from nbformat&gt;=5.0-&gt;nbclient&lt;0.6,&gt;=0.4.0-&gt;voila) (3.2.0) Requirement already satisfied: webencodings in /opt/conda/envs/fastai/lib/python3.8/site-packages (from bleach-&gt;nbconvert&lt;7,&gt;=6.0.0-&gt;voila) (0.5.1) Requirement already satisfied: six&gt;=1.9.0 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from bleach-&gt;nbconvert&lt;7,&gt;=6.0.0-&gt;voila) (1.15.0) Requirement already satisfied: packaging in /opt/conda/envs/fastai/lib/python3.8/site-packages (from bleach-&gt;nbconvert&lt;7,&gt;=6.0.0-&gt;voila) (20.4) Requirement already satisfied: MarkupSafe&gt;=0.23 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from jinja2&gt;=2.4-&gt;nbconvert&lt;7,&gt;=6.0.0-&gt;voila) (1.1.1) Requirement already satisfied: ptyprocess; os_name != &#34;nt&#34; in /opt/conda/envs/fastai/lib/python3.8/site-packages (from terminado&gt;=0.8.3-&gt;jupyter-server&lt;2.0.0,&gt;=0.3.0-&gt;voila) (0.6.0) Requirement already satisfied: idna&gt;=2.8 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from anyio&gt;=2.0.2-&gt;jupyter-server&lt;2.0.0,&gt;=0.3.0-&gt;voila) (2.10) Collecting sniffio&gt;=1.1 Downloading sniffio-1.2.0-py3-none-any.whl (10 kB) Requirement already satisfied: setuptools in /opt/conda/envs/fastai/lib/python3.8/site-packages (from jsonschema!=2.5.0,&gt;=2.4-&gt;nbformat&gt;=5.0-&gt;nbclient&lt;0.6,&gt;=0.4.0-&gt;voila) (49.6.0.post20201009) Requirement already satisfied: pyrsistent&gt;=0.14.0 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from jsonschema!=2.5.0,&gt;=2.4-&gt;nbformat&gt;=5.0-&gt;nbclient&lt;0.6,&gt;=0.4.0-&gt;voila) (0.17.3) Requirement already satisfied: attrs&gt;=17.4.0 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from jsonschema!=2.5.0,&gt;=2.4-&gt;nbformat&gt;=5.0-&gt;nbclient&lt;0.6,&gt;=0.4.0-&gt;voila) (20.3.0) Requirement already satisfied: pyparsing&gt;=2.0.2 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from packaging-&gt;bleach-&gt;nbconvert&lt;7,&gt;=6.0.0-&gt;voila) (2.4.7) Installing collected packages: nbconvert, sniffio, anyio, jupyter-server, voila Attempting uninstall: nbconvert Found existing installation: nbconvert 5.6.1 Uninstalling nbconvert-5.6.1: Successfully uninstalled nbconvert-5.6.1 ERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts. We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default. nbdev 1.1.5 requires nbconvert&lt;6, but you&#39;ll have nbconvert 6.0.7 which is incompatible. Successfully installed anyio-2.1.0 jupyter-server-1.3.0 nbconvert-6.0.7 sniffio-1.2.0 voila-0.2.6 Enabling: voila - Writing config: /opt/conda/envs/fastai/etc/jupyter - Validating... voila 0.2.6 OK .",
            "url": "https://jp97.github.io/SW-AI-Blog/jupyter/2021/02/16/hotdog-classifier.html",
            "relUrl": "/jupyter/2021/02/16/hotdog-classifier.html",
            "date": " • Feb 16, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://jp97.github.io/SW-AI-Blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://jp97.github.io/SW-AI-Blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://jp97.github.io/SW-AI-Blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://jp97.github.io/SW-AI-Blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}